{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d9ab20-42ef-4466-8da6-fa483c7dd56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "config = ['Accounting', 'Agriculture', 'Architecture_and_Engineering', 'Art', 'Art_Theory', 'Basic_Medical_Science', 'Biology', 'Chemistry', 'Clinical_Medicine', 'Computer_Science', 'Design', 'Diagnostics_and_Laboratory_Medicine', 'Economics', 'Electronics', 'Energy_and_Power', 'Finance', 'Geography', 'History', 'Literature', 'Manage', 'Marketing', 'Materials', 'Math', 'Mechanical_Engineering', 'Music', 'Pharmacy', 'Physics', 'Psychology', 'Public_Health', 'Sociology']\n",
    "\n",
    "ds = load_dataset(\"MMMU/MMMU\",config[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d843f56d-b76f-4544-a41e-2359d8761f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_index = 6\n",
    "training_gpu = \"cuda:\"+str(gpu_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c5a92c0-6aa1-40ff-85ba-a02259400c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3cb8c163f14bd284dabfad86e4ff9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlavaNextForConditionalGeneration(\n",
       "  (vision_tower): CLIPVisionModel(\n",
       "    (vision_model): CLIPVisionTransformer(\n",
       "      (embeddings): CLIPVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "        (position_embedding): Embedding(577, 1024)\n",
       "      )\n",
       "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x CLIPEncoderLayer(\n",
       "            (self_attn): CLIPSdpaAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multi_modal_projector): LlavaNextMultiModalProjector(\n",
       "    (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "    (act): GELUActivation()\n",
       "    (linear_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  )\n",
       "  (language_model): MistralForCausalLM(\n",
       "    (model): MistralModel(\n",
       "      (embed_tokens): Embedding(32064, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x MistralDecoderLayer(\n",
       "          (self_attn): MistralSdpaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): MistralRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): MistralMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "processor = LlavaNextProcessor.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\")\n",
    "\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\", torch_dtype=torch.float16, low_cpu_mem_usage=True)\n",
    "model.to(f\"cuda:{gpu_index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c19529d-ad10-4b9c-bfd1-fa60396a4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baukit import Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7514907f-fbff-4e63-884d-1ed4ee0ccc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f13518a0460>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2ee0c6-9f47-47df-9abb-af9c40d95ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f29ec1aa-6a72-4ad6-8b82-9802bb9e84f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINAL'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c106e575-6937-4a66-8f5c-062138af31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 20\n",
    "file = f\"/SAE_imagetext_layer{layer}_models_longrun/\" +os.listdir(f\"/SAE_imagetext_layer{layer}_models_longrun/\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffe12903-3adb-404f-9a08-543bae33389b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3514303/995103250.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sae.load_state_dict(torch.load(file))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(4096,int(8*4096),bias=True) \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(int(8*4096), 4096,bias=True) \n",
    "        self.initialize_weights()\n",
    "    #Biases are initialized to zero, \n",
    "    def initialize_weights(self):\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "        #fun trick, gaussians in high dimensions are uniform \"soap bubbles\"\n",
    "        W_d = torch.randn(self.fc2.weight.size())\n",
    "        W_d = W_d / W_d.norm(dim=1, keepdim=True) * 0.1  # Adjust 0.1 as needed\n",
    "        self.fc2.weight.data = W_d\n",
    "        self.fc1.weight.data = W_d.t()\n",
    "    def forward(self, x):\n",
    "        features = self.relu1(self.fc1(x))\n",
    "        x_hat = self.fc2(features)\n",
    "        return x_hat,features \n",
    "sae = SAE()\n",
    "sae = nn.DataParallel(sae, device_ids=[gpu_index])\n",
    "sae = sae.cuda(device=gpu_index)\n",
    "sae.load_state_dict(torch.load(file))\n",
    "def forward_ablate(text_input,image,tokens):\n",
    "        intervention = intervene\n",
    "        inp = processor(text_input,image, return_tensors=\"pt\").to(training_gpu)\n",
    "        for i in range(tokens):    \n",
    "            with Trace(model.language_model.model.layers[layer-1],edit_output=intervention) as ret:\n",
    "                out = model(**inp)\n",
    "            logits = out.logits[0][-1]\n",
    "            inp['input_ids'] = torch.tensor(np.array(list(inp.input_ids.detach().cpu().numpy()[0])+[torch.argmax(logits).detach().cpu().numpy()])).unsqueeze(0).to(training_gpu)\n",
    "            inp['attention_mask'] = torch.ones((inp['attention_mask'].size(0),inp['attention_mask'].size(1)+1)).int().to(training_gpu)\n",
    "        return inp['input_ids'][0]\n",
    "    \n",
    "def generate_ablate(input_text,imp_image,num_tokens):\n",
    "    ids = forward_ablate(input_text,imp_image,num_tokens)\n",
    "    return processor.decode(ids,skip_special_tokens=True)\n",
    "\n",
    "def intervene(output):\n",
    "    meow = output[0].squeeze(0).float()\n",
    "    meow = sae(meow.unsqueeze(0)*8)[0].squeeze(0)/8\n",
    "    return (meow.unsqueeze(0).half(),output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de6f4343-e301-459e-8483-f177ed37dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_ablate(text_input,image,tokens):\n",
    "        intervention = intervene\n",
    "        inp = processor(text_input,image.resize((336,336)), return_tensors=\"pt\").to(training_gpu)\n",
    "        for i in range(tokens):    \n",
    "            with Trace(model.language_model.model.layers[layer-1],edit_output=intervention) as ret:\n",
    "                out = model(**inp)\n",
    "            logits = out.logits[0][-1]\n",
    "            inp['input_ids'] = torch.tensor(np.array(list(inp.input_ids.detach().cpu().numpy()[0])+[torch.argmax(logits).detach().cpu().numpy()])).unsqueeze(0).to(training_gpu)\n",
    "            inp['attention_mask'] = torch.ones((inp['attention_mask'].size(0),inp['attention_mask'].size(1)+1)).int().to(training_gpu)\n",
    "        return inp['input_ids'][0]\n",
    "    \n",
    "def generate_ablate(input_text,imp_image,num_tokens):\n",
    "    ids = forward_ablate(input_text,imp_image,num_tokens)\n",
    "    return processor.decode(ids,skip_special_tokens=True)\n",
    "\n",
    "def intervene(output):\n",
    "    meow = output[0].squeeze(0).float()\n",
    "    meow[:1183] = sae(meow[:1183].unsqueeze(0)*8)[0].squeeze(0)/8\n",
    "    return (meow.unsqueeze(0).half(),output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665e4afc-ce32-4604-93fe-c60d280545d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1985f986-1220-4fca-a24f-70bbdd29b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_q(i):\n",
    "    q = '[INST] \\<image>\\n '+ds[i]['question'].replace('<image 1>','the image')\n",
    "    options = ast.literal_eval(ds[i]['options'])\n",
    "    letters = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N']\n",
    "    used_letters = []\n",
    "    for j in range(len(options)):\n",
    "        q = q+f\"\\n {letters[j]}: \"+options[j]\n",
    "        used_letters.append(letters[j])\n",
    "    \n",
    "    q = q + f\"\\n Please Answer only answer with one of {used_letters}. Do not provide any explanation. [/INST]\"\n",
    "    images = []\n",
    "    for j in range(1,8):\n",
    "        if ds[i]['image_'+str(j)] is not None:\n",
    "            images.append(ds[i]['image_'+str(j)])\n",
    "    return q,images[0], ds[i]['answer'], len(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06dc6b36-f893-439c-8ff1-191abe3c9c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from transformers import logging\n",
    "\n",
    "# Turn off warnings from the transformers library\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# If you want to suppress all Python warnings, including those from other libraries\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94052829-c1f0-47c3-88fd-ab6f06edef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6825d16-91f9-4b57-a419-f77e3ad91f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.2333 Chance: 0.2944: 100%|█████████████| 30/30 [00:14<00:00,  2.00it/s]\n",
      "MODEL: 0.3 Chance: 0.2542: 100%|████████████████| 30/30 [00:46<00:00,  1.54s/it]\n",
      "MODEL: 0.3014 Chance: 0.258:  47%|██████▌       | 14/30 [00:06<00:07,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.2667 Chance: 0.2574: 100%|█████████████| 30/30 [00:13<00:00,  2.18it/s]\n",
      "MODEL: 0.3333 Chance: 0.2569: 100%|█████████████| 30/30 [00:21<00:00,  1.42it/s]\n",
      "MODEL: 0.3867 Chance: 0.2556: 100%|█████████████| 30/30 [00:22<00:00,  1.32it/s]\n",
      "MODEL: 0.3899 Chance: 0.2551:  33%|████▎        | 10/30 [00:04<00:09,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3804 Chance: 0.2545:  47%|██████       | 14/30 [00:06<00:07,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3944 Chance: 0.2597: 100%|█████████████| 30/30 [00:13<00:00,  2.23it/s]\n",
      "MODEL: 0.381 Chance: 0.2593:  33%|████▋         | 10/30 [00:05<00:10,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3667 Chance: 0.2542: 100%|█████████████| 30/30 [00:17<00:00,  1.70it/s]\n",
      "MODEL: 0.3662 Chance: 0.2543:  13%|█▊            | 4/30 [00:01<00:10,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3604 Chance: 0.2529:  43%|█████▋       | 13/30 [00:05<00:08,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3553 Chance: 0.2511:  63%|████████▏    | 19/30 [00:08<00:05,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3553 Chance: 0.2511:  67%|████████▋    | 20/30 [00:08<00:04,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3491 Chance: 0.2487:  77%|█████████▉   | 23/30 [00:10<00:03,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3462 Chance: 0.2477:  83%|██████████▊  | 25/30 [00:11<00:02,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3431 Chance: 0.2467: 100%|█████████████| 30/30 [00:13<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL: 0.3444 Chance: 0.2438: 100%|█████████████| 30/30 [00:15<00:00,  1.88it/s]\n",
      "MODEL: 0.3417 Chance: 0.244:  30%|████▌          | 9/30 [00:04<00:10,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3356 Chance: 0.2436:  77%|█████████▉   | 23/30 [00:11<00:03,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3322 Chance: 0.2426:  87%|███████████▎ | 26/30 [00:12<00:02,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3333 Chance: 0.2419: 100%|█████████████| 30/30 [00:14<00:00,  2.01it/s]\n",
      "MODEL: 0.3606 Chance: 0.2426: 100%|█████████████| 30/30 [00:17<00:00,  1.70it/s]\n",
      "MODEL: 0.35 Chance: 0.2427: 100%|███████████████| 30/30 [00:26<00:00,  1.15it/s]\n",
      "MODEL: 0.3536 Chance: 0.2449:  67%|████████▋    | 20/30 [00:09<00:04,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3564 Chance: 0.2453: 100%|█████████████| 30/30 [00:14<00:00,  2.08it/s]\n",
      "MODEL: 0.3555 Chance: 0.2459:   7%|▉             | 2/30 [00:00<00:11,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3537 Chance: 0.2453:  13%|█▊            | 4/30 [00:01<00:11,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3537 Chance: 0.2453:  17%|██▎           | 5/30 [00:02<00:10,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3537 Chance: 0.2453:  20%|██▊           | 6/30 [00:02<00:09,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3525 Chance: 0.2435:  37%|████▊        | 11/30 [00:04<00:08,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3525 Chance: 0.2435:  40%|█████▏       | 12/30 [00:05<00:07,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3531 Chance: 0.2424:  53%|██████▉      | 16/30 [00:06<00:05,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3512 Chance: 0.2418:  70%|█████████    | 21/30 [00:08<00:03,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3487 Chance: 0.2413:  80%|██████████▍  | 24/30 [00:10<00:02,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3487 Chance: 0.2413:  83%|██████████▊  | 25/30 [00:10<00:02,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3487 Chance: 0.2413:  87%|███████████▎ | 26/30 [00:11<00:01,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3487 Chance: 0.2413:  90%|███████████▋ | 27/30 [00:11<00:01,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3469 Chance: 0.239:  97%|█████████████▌| 29/30 [00:12<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3469 Chance: 0.239: 100%|██████████████| 30/30 [00:12<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL: 0.3467 Chance: 0.243: 100%|██████████████| 30/30 [00:14<00:00,  2.09it/s]\n",
      "MODEL: 0.3457 Chance: 0.2431:  27%|███▋          | 8/30 [00:03<00:10,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3442 Chance: 0.2426:  33%|████▎        | 10/30 [00:04<00:09,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3412 Chance: 0.2422:  57%|███████▎     | 17/30 [00:07<00:05,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3412 Chance: 0.2417:  67%|████████▋    | 20/30 [00:09<00:04,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.339 Chance: 0.2412:  77%|██████████▋   | 23/30 [00:10<00:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.339 Chance: 0.2412:  80%|███████████▏  | 24/30 [00:10<00:02,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.339 Chance: 0.2412:  83%|███████████▋  | 25/30 [00:11<00:02,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3382 Chance: 0.2398: 100%|█████████████| 30/30 [00:13<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL: 0.3375 Chance: 0.2393:  13%|█▊            | 4/30 [00:01<00:12,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3347 Chance: 0.2391:  47%|██████       | 14/30 [00:06<00:07,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3313 Chance: 0.2396:  73%|█████████▌   | 22/30 [00:11<00:03,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3294 Chance: 0.2394: 100%|█████████████| 30/30 [00:14<00:00,  2.03it/s]\n",
      "MODEL: 0.3407 Chance: 0.2399: 100%|█████████████| 30/30 [00:17<00:00,  1.68it/s]\n",
      "MODEL: 0.3614 Chance: 0.2404: 100%|█████████████| 30/30 [00:16<00:00,  1.78it/s]\n",
      "MODEL: 0.3601 Chance: 0.2405:  10%|█▍            | 3/30 [00:01<00:12,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3584 Chance: 0.2415:  57%|███████▎     | 17/30 [00:08<00:06,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3565 Chance: 0.2411:  67%|████████▋    | 20/30 [00:10<00:04,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3565 Chance: 0.2411:  70%|█████████    | 21/30 [00:10<00:04,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3547 Chance: 0.2403:  77%|█████████▉   | 23/30 [00:11<00:03,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3535 Chance: 0.2398:  83%|██████████▊  | 25/30 [00:12<00:02,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3517 Chance: 0.2398: 100%|█████████████| 30/30 [00:15<00:00,  1.98it/s]\n",
      "MODEL: 0.3475 Chance: 0.2407:  37%|████▊        | 11/30 [00:05<00:09,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3476 Chance: 0.2411: 100%|█████████████| 30/30 [00:15<00:00,  1.90it/s]\n",
      "MODEL: 0.3409 Chance: 0.2417: 100%|█████████████| 30/30 [00:14<00:00,  2.07it/s]\n",
      "MODEL: 0.3457 Chance: 0.2424:  50%|██████▌      | 15/30 [00:07<00:06,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3464 Chance: 0.2428: 100%|█████████████| 30/30 [00:14<00:00,  2.10it/s]\n",
      "MODEL: 0.3444 Chance: 0.2447: 100%|█████████████| 30/30 [00:14<00:00,  2.14it/s]\n",
      "MODEL: 0.344 Chance: 0.2466: 100%|██████████████| 30/30 [00:17<00:00,  1.75it/s]\n",
      "MODEL: 0.3444 Chance: 0.2466:  10%|█▍            | 3/30 [00:01<00:12,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3424 Chance: 0.2481:  63%|████████▏    | 19/30 [00:08<00:04,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3432 Chance: 0.2479:  87%|███████████▎ | 26/30 [00:11<00:02,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3423 Chance: 0.2477: 100%|█████████████| 30/30 [00:13<00:00,  2.19it/s]\n",
      "MODEL: 0.34 Chance: 0.2477:  70%|██████████▌    | 21/30 [00:09<00:04,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3395 Chance: 0.2473: 100%|█████████████| 30/30 [00:13<00:00,  2.17it/s]\n",
      "MODEL: 0.3366 Chance: 0.2468:  67%|████████▋    | 20/30 [00:11<00:05,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MODEL: 0.3381 Chance: 0.2464: 100%|█████████████| 30/30 [00:18<00:00,  1.64it/s]\n",
      "MODEL: 0.3414 Chance: 0.2465: 100%|█████████████| 30/30 [00:14<00:00,  2.10it/s]\n",
      "MODEL: 0.3433 Chance: 0.247: 100%|██████████████| 30/30 [00:20<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3433333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "cnt = 0\n",
    "tot = 0\n",
    "chance = 0\n",
    "\n",
    "for l in range(len(config)):\n",
    "    ds = load_dataset(\"MMMU/MMMU\",config[l])\n",
    "    ds = ds['validation']\n",
    "    pbar = tqdm(range(30))\n",
    "    for i in pbar:\n",
    "        prompt, images, answer,num_answers = load_q(i)\n",
    "        try:\n",
    "            inputs = processor(images, prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "            \n",
    "            # autoregressively complete prompt\n",
    "            \n",
    "            \n",
    "            # autoregressively complete prompt\n",
    "            output = generate_ablate(prompt,images,1)\n",
    "            \n",
    "            rep = output[-1]\n",
    "            if rep == answer:\n",
    "                cnt+=1\n",
    "                \n",
    "            tot +=1\n",
    "            chance+=1/num_answers\n",
    "            pbar.set_description(\"MODEL: \"+str(round(cnt/tot, 4)) + \" Chance: \"+ str(round(chance/tot, 4)))\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except:\n",
    "            print(\"sadge\")\n",
    "        \n",
    "print(cnt/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59eee585-35ac-402e-9cc8-2f7343a55e1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# autoregressively complete prompt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_ablate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m rep \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rep \u001b[38;5;241m==\u001b[39m answer:\n",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m, in \u001b[0;36mgenerate_ablate\u001b[0;34m(input_text, imp_image, num_tokens)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_ablate\u001b[39m(input_text,imp_image,num_tokens):\n\u001b[0;32m---> 13\u001b[0m     ids \u001b[38;5;241m=\u001b[39m \u001b[43mforward_ablate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimp_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processor\u001b[38;5;241m.\u001b[39mdecode(ids,skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m, in \u001b[0;36mforward_ablate\u001b[0;34m(text_input, image, tokens)\u001b[0m\n\u001b[1;32m      6\u001b[0m         out \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minp)\n\u001b[1;32m      7\u001b[0m     logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m     inp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(inp\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m+\u001b[39m[torch\u001b[38;5;241m.\u001b[39margmax(logits)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(training_gpu)\n\u001b[1;32m      9\u001b[0m     inp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((inp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),inp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39mto(training_gpu)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "            \n",
    "# autoregressively complete prompt\n",
    "output = generate_ablate(prompt,images,1)\n",
    "\n",
    "rep = output[-1]\n",
    "if rep == answer:\n",
    "    cnt+=1\n",
    "if rep not in ['A','B','C','D','E','F','G','H','I','J','K','L','M','N']:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96612004-226f-4e86-a4b7-94d4e3987ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] Donna Donie, CFA, has a client who believes the common stock price of TRT Materials (currently $58 per share) could move substantially in either direction in reaction to an expected court decision involving the company. The client currently owns no TRT shares, but asks Donie for advice about implementing a strangle strategy to capitalize on the possible stock price movement. A strangle is a portfolio of a put and a call with different exercise prices but the same expiration date. Donie gathers the TRT option-pricing data: \n",
      " \n",
      " Calculate, at expiration for long strangle strategy, the Maximum possible loss per share.\n",
      " A: $9.00\n",
      " B: $5.00\n",
      " C: the Maximum  possible loss is unlimited\n",
      " Please Answer only answer with one of ['A', 'B', 'C']. Do not provide any explanation. [/INST]5 25,\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cc289de-4bc8-4a96-aa1a-34256a07fa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[INST] Donna Donie, CFA, has a client who believes the common stock price of TRT Materials (currently $58 per share) could move substantially in either direction in reaction to an expected court decision involving the company. The client currently owns no TRT shares, but asks Donie for advice about implementing a strangle strategy to capitalize on the possible stock price movement. A strangle is a portfolio of a put and a call with different exercise prices but the same expiration date. Donie gathers the TRT option-pricing data: \\n \\n Calculate, at expiration for long strangle strategy, the Maximum possible loss per share.\\n A: $9.00\\n B: $5.00\\n C: the Maximum  possible loss is unlimited\\n Please Answer only answer with one of ['A', 'B', 'C']. Do not provide any explanation. [/INST]5\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bda0a03d-43a5-4d3e-b5cc-c09903ef9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "909b8598-32f5-4094-b6bd-4dec23f35b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.pad_token_id=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c54b33-a4d1-4ffc-a80f-045c61018cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "556e9996-6645-443b-8500-8ea5bf40ae63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Visual elements'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c07da2dd-6edf-45f0-89d3-ce34886498a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Which of the following best explains the overall trend shown in the <image>?\\n A: [\\n B: '\\n C: M\\n D: M\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9483dcef-2c18-4295-aad9-fdf59943623c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: num_additional_image_tokens. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff190ed29f3f4a6ea681f4a9ede59c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlavaNextForConditionalGeneration(\n",
       "  (vision_tower): CLIPVisionModel(\n",
       "    (vision_model): CLIPVisionTransformer(\n",
       "      (embeddings): CLIPVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "        (position_embedding): Embedding(577, 1024)\n",
       "      )\n",
       "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x CLIPEncoderLayer(\n",
       "            (self_attn): CLIPSdpaAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multi_modal_projector): LlavaNextMultiModalProjector(\n",
       "    (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "    (act): GELUActivation()\n",
       "    (linear_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  )\n",
       "  (language_model): MistralForCausalLM(\n",
       "    (model): MistralModel(\n",
       "      (embed_tokens): Embedding(32064, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x MistralDecoderLayer(\n",
       "          (self_attn): MistralSdpaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): MistralRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): MistralMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df742882-7b3a-4ba3-894b-952bc028c01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (3.0.3)\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2) (2.0.1)\n",
      "Installing collected packages: jinja2\n",
      "Successfully installed jinja2-3.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9a9d2-445b-4184-b3c2-c360e2db86bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
